in prometheus what we are use for pull metrics from target server  ?
1) Node Exporter (MOST COMMON) --> Used to pull OS/server metrics:
-------------
2. Application-Specific Exporters-->
Based on what service you want to monitor:
Blackbox Exporter â†’ Ping, HTTP, TCP checks
MySQL Exporter â†’ DB metrics
MongoDB Exporter
Nginx Exporter
Redis Exporter
Kafka Exporter
JMX Exporter â†’ Java apps
-------------------
Q. how to install AWS Karpenter in an EKS cluster ? via helm chart
Q. Cluster auto scaler is working together with karpenter ?
No â€” Cluster Autoscaler (CA) and Karpenter should NOT run together.
Karpenter:-->
Works at individual EC2 instance level (not ASG).
Launches nodes directly using EC2 Fleet
Very fast (10â€“30 seconds)
-----------------------------------------------------------
Cluster Autoscaler (CA): --> ðŸ‘‰ Use either Karpenter OR Cluster Autoscaler â€” not both.
Works at Auto Scaling Group / Node Group level
Adds/removes nodes inside ASG
Slow scaling (3â€“5 minutes)
==========================================
Q. for cluster auto scaler we have .yaml file helm provide .yaml file ?
--> Yes â€” Cluster Autoscaler is installed using Helm, and Helm will provide the YAML manifests for you.
===================
In AWS â†’ ALB Ingress can handle many micro-services
--> Because each service gets its own target group.
--------------------------------
Yes â€” ClusterIP services in Kubernetes DO get an virtual IP address.
Host-based routing:
api.myapp.com  -> service: api-service
auth.myapp.com -> service: auth-service
------------------------
Path-based routing:
/api   -> api-service
/auth  -> auth-service
/cart  -> cart-service
------------------------------
Yes, ClusterIP acts like an internal proxy/load balancer for backend pods.
------------------
When you create a Service with type: ClusterIP, Kubernetes assigns it a virtual IP address (VIP) inside the cluster only.
-----------------------------------------
# kubectl get svc
my-service   ClusterIP   10.0.123.45   <none>   80/TCP   10m
--> Here, 10.0.123.45 is the ClusterIP.        Used by pods to talk to other services
--------------------------------------------------------------------------
âœ” How to test the ClusterIP? From a pod:
--> curl http://my-service:80
or using the IP: curl http://10.xx.xx.xx:80
It is internal only â†’ accessible inside the cluster
-----------------------------
Q. if i m using service type is cluster ip then who give dns name to my service ?
âœ… Who gives DNS to your ClusterIP service?
ðŸ‘‰ CoreDNS (Kubernetes DNS server)
------------------------------------------
Q. if i m using service type is cluster ip then that service have port number ?
--> âœ… ClusterIP has:
An IP address (internal VIP)
A Port (Service Port)
A TargetPort (Pod port)
-----------------------------------------------------
NAME         TYPE        CLUSTER-IP     PORT(S)
my-service   ClusterIP   10.0.12.5      80/TCP
----------------------------------------
apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  type: ClusterIP
  selector:
    app: my-app
  ports:
  - port: 80        # Service Port
    targetPort: 8080 # Pod Port
--------------------------------------------
âœ” Pod runs app on 8080
âœ” Service listens on 80
âœ” Service forwards 80 â†’ 8080
-----------------------------
ðŸ”¹ What if you don't specify port?

âŒ Service will NOT work.
A Service must define at least one port.
-------------------------------------
Q. How Ingress maps HTTP to service ports ?
------------------------------
You can access it inside the cluster: -->
curl http://my-service
curl http://my-service.default
curl http://my-service.default.svc
curl http://my-service.default.svc.cluster.local
-----------------------------------------------
ðŸ”¹ DNS structure created by CoreDNS:-->
<service-name>.<namespace>.svc.cluster.local
Examples:
api.default.svc.cluster.local
db.prod.svc.cluster.local
backend.dev.svc.cluster.local
-----------------------------------------------
ALB Ingress with sticky sessions
---------------------------
Q.if i hv front end pods then i need to use which service type for my nginx ?
-------------
If you have front-end pods (React/Angular/Vue/HTML) served by NGINX, the correct service type depends on how you want to expose it.
----------------------------------
AWS ALB Ingress example for a front-end (NGINX) service running in EKS. (AWS Load Balancer Controller)
---------------------
ALB Ingress with multiple microservices
-----------------------------
Hereâ€™s a production-ready example of AWS ALB Ingress with multiple microservices in an EKS cluster. This setup is used in real-world scenarios 
where different services (frontend, backend, auth) are exposed via one ALB using host- or path-based routing.
-----------------------
âœ… 3. Important Notes for Prod

Services must be ClusterIP â€” Ingress handles public exposure.
TLS (HTTPS) must be configured in annotations (certificate-arn).
Health checks should be configured (/health endpoint for backend).
Path and host rules determine which service receives traffic.
Works with ALB Ingress Controller in AWS EKS.
----------------------------------------
in k8s :
in production, the routing rules for front-end and backend microservices are typically configured in the Ingress resource YAML (ingress.yaml) ? Yes
-------------------------------------------------------
if our app in not containerised then front end is talked to backend that we configured via ? I think front end is separate and backend is separate ?
------------------------------------------------------
i hv backend pod that will communicate with db so I hv aws RDS DB so in config map db related things are same for each backend services ?
--> Yes â€” in Kubernetes, if you have multiple backend pods (or services) that all need to connect to the same AWS RDS database, 
the DB-related configuration is typically the same for each backend service, but it depends on how you manage secrets and config. 
------------------------------------------------------------------------------------------------------------
Use environment variables or volume mounts to inject the values into pods.
----------------------------------
env:
        - name: DB_HOST
          valueFrom:
            configMapKeyRef:
              name: db-config
              key: DB_HOST
----------------------------------------
valueFrom:
            secretKeyRef:
              name: db-secret
              key: DB_USER
        - name: DB_PASS
          valueFrom:
            secretKeyRef:
              name: db-secret
              key: DB_PASS
------------------------------------------------------
so headless service is provide dns name to each pod in statefulset app like mysql use case ?

For a StatefulSet named mysql with a Headless Service named mysql-headless and 3 replicas, the DNS entries would be:
mysql-0.mysql-headless.default.svc.cluster.local (resolves to Pod mysql-0's IP)

mysql-1.mysql-headless.default.svc.cluster.local (resolves to Pod mysql-1's IP)

mysql-2.mysql-headless.default.svc.cluster.local (resolves to Pod mysql-2's IP)

The pod name (and thus the DNS entry) remains the same even if the pod dies and is rescheduled to a new node with a different IP address.
This is the stable network identity required by the StatefulSet.
------------------------------------------------------
Q. how your backend pods authenticates to RDS ?
RDS read replica & RDS *endpoint* we keep in config map & secret 
RDS  username/password
----------------------------------------------
ExternalName is service type
if I m using eks then RDS as a database then backend is talk with Database so in backend service.yaml I need to use service type is cluster IP or headless service ?
----------------------------
